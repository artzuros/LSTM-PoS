{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### One-Hot Encoding #####\n",
    "def one_hot_encode(indices, vocab_size):\n",
    "    tensor = torch.zeros(vocab_size)\n",
    "    for idx in indices:\n",
    "        if idx < vocab_size:\n",
    "            tensor[idx] = 1\n",
    "    return tensor.view(1, -1)  # Reshape to (1, vocab_size)\n",
    "\n",
    "\n",
    "##### Xavier Normalized Initialization #####\n",
    "def init_weights(input_size, output_size):\n",
    "    return torch.FloatTensor(output_size, input_size).uniform_(-1, 1) * torch.sqrt(torch.tensor(6.0) / (input_size + output_size))\n",
    "\n",
    "##### Activation Functions #####\n",
    "def sigmoid(input, derivative=False):\n",
    "    if derivative:\n",
    "        return input * (1 - input)\n",
    "    return 1 / (1 + torch.exp(-input))\n",
    "\n",
    "def tanh(input, derivative=False):\n",
    "    if derivative:\n",
    "        return 1 - input ** 2\n",
    "    return torch.tanh(input)\n",
    "\n",
    "def softmax(input):\n",
    "    return F.softmax(input, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "##### Long Short-Term Memory Network Class #####\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_epochs, learning_rate):\n",
    "        super(LSTM, self).__init__()\n",
    "        # Hyperparameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_epochs = num_epochs\n",
    "\n",
    "        # Forget Gate\n",
    "        self.wf = torch.nn.Parameter(init_weights(input_size + hidden_size, hidden_size))\n",
    "        self.bf = torch.nn.Parameter(torch.zeros(hidden_size, 1))\n",
    "\n",
    "        # Input Gate\n",
    "        self.wi = torch.nn.Parameter(init_weights(input_size + hidden_size, hidden_size))\n",
    "        self.bi = torch.nn.Parameter(torch.zeros(hidden_size, 1))\n",
    "\n",
    "        # Candidate Gate\n",
    "        self.wc = torch.nn.Parameter(init_weights(input_size + hidden_size, hidden_size))\n",
    "        self.bc = torch.nn.Parameter(torch.zeros(hidden_size, 1))\n",
    "\n",
    "        # Output Gate\n",
    "        self.wo = torch.nn.Parameter(init_weights(input_size + hidden_size, hidden_size))\n",
    "        self.bo = torch.nn.Parameter(torch.zeros(hidden_size, 1))\n",
    "\n",
    "        # Final Gate\n",
    "        self.wy = torch.nn.Parameter(init_weights(hidden_size, output_size))\n",
    "        self.by = torch.nn.Parameter(torch.zeros(output_size, 1))\n",
    "\n",
    "\n",
    "    # Reset Network Memory\n",
    "    def reset(self):\n",
    "        self.concat_inputs = {}\n",
    "\n",
    "        self.hidden_states = {-1: torch.zeros((self.hidden_size, 1))}\n",
    "        self.cell_states = {-1: torch.zeros((self.hidden_size, 1))}\n",
    "\n",
    "        self.activation_outputs = {}\n",
    "        self.candidate_gates = {}\n",
    "        self.output_gates = {}\n",
    "        self.forget_gates = {}\n",
    "        self.input_gates = {}\n",
    "        self.outputs = {}\n",
    "\n",
    "    # Forward Propagation\n",
    "    def forward(self, inputs):\n",
    "        self.reset()\n",
    "\n",
    "        outputs = []\n",
    "        for q in range(len(inputs)):\n",
    "            # Move self.hidden_states[q - 1] to the same device as input\n",
    "            self.hidden_states[q - 1] = self.hidden_states[q - 1].to(inputs[q].device)\n",
    "\n",
    "            # Reshape input to match the size of hidden state\n",
    "            input_reshaped = inputs[q].view(-1, 1)\n",
    "\n",
    "            self.concat_inputs[q] = torch.cat((self.hidden_states[q - 1], input_reshaped))\n",
    "\n",
    "            self.forget_gates[q] = sigmoid(torch.matmul(self.wf, self.concat_inputs[q]) + self.bf)\n",
    "            self.input_gates[q] = sigmoid(torch.matmul(self.wi, self.concat_inputs[q]) + self.bi)\n",
    "            self.candidate_gates[q] = tanh(torch.matmul(self.wc, self.concat_inputs[q]) + self.bc)\n",
    "            self.output_gates[q] = sigmoid(torch.matmul(self.wo, self.concat_inputs[q]) + self.bo)\n",
    "\n",
    "            # Move self.cell_states[q - 1] to the same device as input\n",
    "            self.cell_states[q - 1] = self.cell_states[q - 1].to(inputs[q].device)\n",
    "\n",
    "            # Perform computation on the same device\n",
    "            self.cell_states[q] = self.forget_gates[q] * self.cell_states[q - 1] + self.input_gates[q] * self.candidate_gates[q]\n",
    "            self.hidden_states[q] = self.output_gates[q] * tanh(self.cell_states[q])\n",
    "\n",
    "            outputs.append(torch.matmul(self.wy, self.hidden_states[q]) + self.by)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    # Backward Propagation\n",
    "    def backward(self, errors, inputs):\n",
    "        dwf, dbf = 0, 0\n",
    "        dwi, dbi = 0, 0\n",
    "        dwc, dbc = 0, 0\n",
    "        dwo, dbo = 0, 0\n",
    "        dwy, dby = 0, 0\n",
    "\n",
    "        dh_next, dc_next = torch.zeros_like(self.hidden_states[0]), torch.zeros_like(self.cell_states[0])\n",
    "        for q in reversed(range(len(inputs))):\n",
    "            error = errors[q]\n",
    "\n",
    "            # Final Gate Weights and Biases Errors\n",
    "            dwy += torch.matmul(error, self.hidden_states[q].T)\n",
    "            dby += error\n",
    "\n",
    "            # Hidden State Error\n",
    "            d_hs = torch.matmul(self.wy.T, error) + dh_next\n",
    "\n",
    "            # Output Gate Weights and Biases Errors\n",
    "            d_o = tanh(self.cell_states[q]) * d_hs * sigmoid(self.output_gates[q], derivative=True)\n",
    "            dwo += torch.matmul(d_o, inputs[q].T)\n",
    "            dbo += d_o\n",
    "\n",
    "            # Cell State Error\n",
    "            d_cs = tanh(tanh(self.cell_states[q]), derivative=True) * self.output_gates[q] * d_hs + dc_next\n",
    "\n",
    "            # Forget Gate Weights and Biases Errors\n",
    "            d_f = d_cs * self.cell_states[q - 1] * sigmoid(self.forget_gates[q], derivative=True)\n",
    "            dwf += torch.matmul(d_f, inputs[q].T)\n",
    "            dbf += d_f\n",
    "\n",
    "            # Input Gate Weights and Biases Errors\n",
    "            d_i = d_cs * self.candidate_gates[q] * sigmoid(self.input_gates[q], derivative=True)\n",
    "            dwi += torch.matmul(d_i, inputs[q].T)\n",
    "            dbi += d_i\n",
    "\n",
    "            # Candidate Gate Weights and Biases Errors\n",
    "            d_c = d_cs * self.input_gates[q] * tanh(self.candidate_gates[q], derivative=True)\n",
    "            dwc += torch.matmul(d_c, inputs[q].T)\n",
    "            dbc += d_c\n",
    "\n",
    "            # Concatenated Input Error (Sum of Error at Each Gate!)\n",
    "            d_z = torch.matmul(self.wf.T, d_f) + torch.matmul(self.wi.T, d_i) + torch.matmul(self.wc.T, d_c) + torch.matmul(self.wo.T, d_o)\n",
    "\n",
    "            # Error of Hidden State and Cell State at Next Time Step\n",
    "            dh_next = d_z[:self.hidden_size, :]\n",
    "            dc_next = self.forget_gates[q] * d_cs\n",
    "\n",
    "        for d_ in (dwf, dbf, dwi, dbi, dwc, dbc, dwo, dbo, dwy, dby):\n",
    "            torch.clamp_(d_, -1, 1)\n",
    "\n",
    "        self.wf.data += dwf * self.learning_rate\n",
    "        self.bf.data += dbf * self.learning_rate\n",
    "\n",
    "        self.wi.data += dwi * self.learning_rate\n",
    "        self.bi.data += dbi * self.learning_rate\n",
    "\n",
    "        self.wc.data += dwc * self.learning_rate\n",
    "        self.bc.data += dbc * self.learning_rate\n",
    "\n",
    "        self.wo.data += dwo * self.learning_rate\n",
    "        self.bo.data += dbo * self.learning_rate\n",
    "\n",
    "        self.wy.data += dwy * self.learning_rate\n",
    "        self.by.data += dby * self.learning_rate\n",
    "\n",
    "    # Train\n",
    "    def train(self, inputs, labels):\n",
    "        for _ in tqdm(range(self.num_epochs)):\n",
    "            predictions = self.forward(inputs)\n",
    "\n",
    "            errors = []\n",
    "            for q in range(len(predictions)):\n",
    "                error = -softmax(predictions[q])\n",
    "                label_index = labels[q].argmax().item()  # Convert label tensor to integer\n",
    "                error[label_index] += 1\n",
    "                errors.append(error)\n",
    "\n",
    "            self.backward(errors, self.concat_inputs)\n",
    "\n",
    "    # Test\n",
    "    def test(self, inputs, labels):\n",
    "        accuracy = 0\n",
    "        probabilities = self.forward(inputs)\n",
    "\n",
    "        output = ''\n",
    "        for q in range(len(labels)):\n",
    "            prediction_index = torch.multinomial(softmax(probabilities[q].reshape(-1)), 1).item()\n",
    "            output += str(prediction_index)  # Store prediction index instead of character\n",
    "\n",
    "            # Convert label tensor to integer for comparison\n",
    "            label_index = labels[q].item()\n",
    "            if prediction_index == label_index:\n",
    "                accuracy += 1\n",
    "\n",
    "        print(f'Ground Truth:\\n{labels}\\n')\n",
    "        print(f'Predictions:\\n{output}\\n')\n",
    "\n",
    "        print(f'Accuracy: {round(accuracy * 100 / len(inputs), 2)}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = treebank.tagged_sents()\n",
    "sentences = list(sentences)\n",
    "\n",
    "random.seed(7)\n",
    "random.shuffle(sentences)\n",
    "train_size = int(0.8 * len(sentences))\n",
    "train_sentences = sentences[:train_size]\n",
    "test_sentences = sentences[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words, train_tags = zip(*[(word, tag) for sent in train_sentences for word, tag in sent])\n",
    "test_words, test_tags = zip(*[(word, tag) for sent in test_sentences for word, tag in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocabulary and tag set\n",
    "word_counts = Counter(train_words)\n",
    "tag_counts = Counter(train_tags)\n",
    "word_to_idx = {word: idx for idx, (word, _) in enumerate(word_counts.most_common(), 1)}\n",
    "tag_to_idx = {tag: idx for idx, (tag, _) in enumerate(tag_counts.most_common(), 1)}\n",
    "idx_to_tag = {idx: tag for tag, idx in tag_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a default index for the 'O' tag\n",
    "tag_to_idx.setdefault('O', len(tag_to_idx) + 1)\n",
    "\n",
    "# Convert words and tags into numerical indices\n",
    "train_input_indices = [[word_to_idx.get(word, 0) for word in sent] for sent in train_words]\n",
    "train_label_indices = [[tag_to_idx.get(tag, 0) for tag in sent] for sent in train_tags]\n",
    "test_input_indices = [[word_to_idx.get(word, 0) for word in sent] for sent in test_words]\n",
    "test_label_indices = [[tag_to_idx.get(tag, 0) for tag in sent] for sent in test_tags]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gunub\\AppData\\Local\\Temp\\ipykernel_11216\\1017851377.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_inputs = [torch.tensor(one_hot_encode(indices, len(word_to_idx))).float() for indices in train_input_indices]\n",
      "C:\\Users\\gunub\\AppData\\Local\\Temp\\ipykernel_11216\\1017851377.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = [torch.tensor(one_hot_encode(indices, tag_vocab_size)).float() for indices in train_label_indices]\n",
      "C:\\Users\\gunub\\AppData\\Local\\Temp\\ipykernel_11216\\1017851377.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_inputs = [torch.tensor(one_hot_encode(indices, len(word_to_idx))).float() for indices in test_input_indices]\n",
      "C:\\Users\\gunub\\AppData\\Local\\Temp\\ipykernel_11216\\1017851377.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_labels = [torch.tensor(one_hot_encode(indices, tag_vocab_size)).float() for indices in test_label_indices]\n"
     ]
    }
   ],
   "source": [
    "# Determine the size of the vocabulary for tags\n",
    "tag_vocab_size = len(tag_to_idx)\n",
    "\n",
    "# Convert indices into one-hot encoded vectors\n",
    "train_inputs = [torch.tensor(one_hot_encode(indices, len(word_to_idx))).float() for indices in train_input_indices]\n",
    "train_labels = [torch.tensor(one_hot_encode(indices, tag_vocab_size)).float() for indices in train_label_indices]\n",
    "test_inputs = [torch.tensor(one_hot_encode(indices, len(word_to_idx))).float() for indices in test_input_indices]\n",
    "test_labels = [torch.tensor(one_hot_encode(indices, tag_vocab_size)).float() for indices in test_label_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the LSTM model\n",
    "input_size = len(word_to_idx)\n",
    "output_size = len(tag_to_idx)\n",
    "hidden_size = 128\n",
    "num_epochs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "pos_tagger = LSTM(input_size, hidden_size, output_size, num_epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11016"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the model to the GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pos_tagger.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert inputs and labels to CUDA tensors\n",
    "train_inputs = [input_tensor.to(device) for input_tensor in train_inputs]\n",
    "train_labels = [label_tensor.to(device) for label_tensor in train_labels]\n",
    "test_inputs = [input_tensor.to(device) for input_tensor in test_inputs]\n",
    "test_labels = [label_tensor.to(device) for label_tensor in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [28:17<12:52, 257.55s/it]"
     ]
    }
   ],
   "source": [
    "pos_tagger.train(train_inputs, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training\n",
    "torch.save(pos_tagger.state_dict(), 'pos_tagger_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LSTM:\n\tsize mismatch for wf: copying a param with shape torch.Size([128, 11176]) from checkpoint, the shape in current model is torch.Size([128, 11098]).\n\tsize mismatch for wi: copying a param with shape torch.Size([128, 11176]) from checkpoint, the shape in current model is torch.Size([128, 11098]).\n\tsize mismatch for wc: copying a param with shape torch.Size([128, 11176]) from checkpoint, the shape in current model is torch.Size([128, 11098]).\n\tsize mismatch for wo: copying a param with shape torch.Size([128, 11176]) from checkpoint, the shape in current model is torch.Size([128, 11098]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m pos_tagger \u001b[38;5;241m=\u001b[39m LSTM(input_size, hidden_size, output_size, num_epochs, learning_rate)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mpos_tagger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpos_tagger_model.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mh:\\Python3_10\\lib\\site-packages\\torch\\nn\\modules\\module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   2036\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2037\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2038\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2042\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LSTM:\n\tsize mismatch for wf: copying a param with shape torch.Size([128, 11176]) from checkpoint, the shape in current model is torch.Size([128, 11098]).\n\tsize mismatch for wi: copying a param with shape torch.Size([128, 11176]) from checkpoint, the shape in current model is torch.Size([128, 11098]).\n\tsize mismatch for wc: copying a param with shape torch.Size([128, 11176]) from checkpoint, the shape in current model is torch.Size([128, 11098]).\n\tsize mismatch for wo: copying a param with shape torch.Size([128, 11176]) from checkpoint, the shape in current model is torch.Size([128, 11098])."
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "pos_tagger = LSTM(input_size, hidden_size, output_size, num_epochs, learning_rate)\n",
    "pos_tagger.load_state_dict(torch.load('pos_tagger_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "pos_tagger.test(test_inputs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wf torch.Size([128, 11176])\n",
      "bf torch.Size([128, 1])\n",
      "wi torch.Size([128, 11176])\n",
      "bi torch.Size([128, 1])\n",
      "wc torch.Size([128, 11176])\n",
      "bc torch.Size([128, 1])\n",
      "wo torch.Size([128, 11176])\n",
      "bo torch.Size([128, 1])\n",
      "wy torch.Size([47, 128])\n",
      "by torch.Size([47, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "saved_model = torch.load('pos_tagger_model.pth')\n",
    "for name, param in saved_model.items():\n",
    "    print(name, param.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
